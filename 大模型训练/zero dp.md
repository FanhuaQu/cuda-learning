在同目录下的存储笔记中，记录了模型训练中需要存储的东西以及占用显存量的计算

在训练过程中，很多参数并不是时时刻刻都用到的，例如：

* adam优化器的states($$m_t、v_t$$)只在最后做update的时候用到
* dp的时候，gradients只在最后做update的时候才用到
* 参数W只在做fwd和bwd那一刻才用到
* ......

Zero的思想就是，将这部分参数用完之后就删除，到需要用到的时候再拉过来，这样就节省了宝贵的显存资源

沿着这个思路，递进来看Zero是怎么做存储优化的

# 1. $$P_{os}$$: 优化状态分割

将优化器状态分成若干份，每个GPU上维护一份，减小了这部分的显存开销

![image-20251013000627797](C:\Users\Qufanhua\AppData\Roaming\Typora\typora-user-images\image-20251013000627797.png)

整体流程如下：

* 每块GPU上存完整的参数W，将一个batch分成3份，每块GPU吃一份，做完一轮fwd和bwd之后，得到各自的梯度G
* 对梯度做一次AllReduce，得到完整的梯度G，通信量是$$2\Phi$$，在Zero1的早期代码中，这里用的是AllReduce，实际上因为每张卡只有部分优化器参数，梯度只做ReduceScatter就行了，这样的通信量是$$\Phi$$。(梯度的作用就是更新优化器参数，所以只需要用于更新优化器参数的部分梯度就行)
* 得到完整的梯度之后，更新本地的那部分优化器参数，然后由优化器参数更新部分权重W(**注意：**这里更新的是fp32的参数，fp16的参数是由fp32 cast得到的)
* 对W做一次All-Gather，在这之前做了`fp16._copy(fp32)`，这样每张卡就拿到了完整的权重，能够进行正常地fwd阶段了。通信量增加是$$\Phi$$

分析一下优化前后的显存占用和单卡通信量(Adam: K = 12)

* 朴素的DP：显存占用$$(2 + 2 + K)\Phi$$，单卡通信量$$2\Phi$$
* $$P_{os}$$：显存占用$$(2 + 2 + \frac{K}{N_d})\Phi$$，单卡通信量$$\Phi$$

假设$$\Phi=7.5B$$，$$N_d=64$$，显存占用从120GB将为了31.4GB

Zero的思想是用通信换显存，类似的思想随处可见！













参考：

https://zhuanlan.zhihu.com/p/618865052



