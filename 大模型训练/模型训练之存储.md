我们经常会说一个模型训练需要占用多大的显存，这是怎么计算得到的呢？

来分析一下混合精度训练需要存储哪些东西：

* 模型参数，包括权重矩阵、偏置等，对于混合精度训练来说，通常模型参数是fp16或者是bf16的(后面整理一下)，**占用2byte**
* 梯度：梯度，梯度是反向传播过程中计算的，用于更新优化器参数，也是fp16或者bf16，**占用2byte**
* 优化器参数，以常用的Adam为例，需要存动量(momentum)和方差(gradients)，为了保证精度，都是用的fp32存，**占用4byte**
* 一份高精度的模型参数副本，用于update的时候参与计算，fp32存，占用**4byte**

综上，光是模型参数和优化器参数，就需要$$16\theta$$，除此之外，可能还会存储一下前向传播的激活值，用于反向传播时计算梯度

训练中迭代一次包括三个阶段：

- 梯度计算(bwd)

反向传播计算每个参数的梯度
$$
g_t = \frac{\partial{L}}{\partial{\theta_t}}
$$

* 优化器状态更新

  adam维护了两个"滑动平均变量"：

  * 一阶矩(动量)：梯度的指数加权平均$$m_t$$。(追踪梯度的平均趋势)
  * 二阶矩：梯度平方的指数加权平均$$v_t$$。(追踪梯度平方的平均趋势)

* 参数更新(update)

  * 利用校正后的$$m_t$$、$$v_t$$调整参数$$\theta$$

这部分计算流程如下

对于每个参数$$\theta$$，首先初始化
$$
m_0=0, v_0=0, t=0
$$
计算梯度$$g_t$$

更新一阶与二阶矩估计
$$
m_t = \beta_{1}m_{t-1}+（1-\beta_1）g_t \\
v_t = \beta_{2}v_{t-1}+(1-\beta_2)g_{t}^2
$$
偏差修正
$$
\hat{m}_t = \frac{m_{t}}{1-\beta_{1}^{t}} \\
\hat{v_t} = \frac{v_t}{1-\beta_{2}^{t}}
$$
参数更新
$$
\theta_t = \theta_{t-1} - \alpha \frac{\hat{m_t}}{\sqrt{\hat{v_t}}+\epsilon}
$$
这里面的$$\theta_{t-1}$$就是用fp32存的

**激活值存储开销和以下因素有关：**

* 不仅和模型参数有关，还和batch size有关
* 激活值存储并不是必须的，也可以在bwd的时候重计算一下(重新从输入x走一遍fwd流程)，实际上不会这么极端





